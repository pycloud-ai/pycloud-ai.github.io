{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to PyCloud! PyCloud is a solution for creating scalable cloud deployments with Python. It translates local Python code into kubernetes cluster with minimal number of extra logic (no more handcrafting yaml files). That allows easy and fast transformation of algorithms/AI code into cloud environment. Because it's fast, it gives flexibility not known before - adjusting architecture/redeployment for better scalability can be done in minutes. Getting started Create and enter python virtualenv virtualenv -p python3 .venv && . .venv3/bin/activate Download pycloud-cli from https://pycloud.ai/download Run pycloud-cli init command Check and download one of the examples on github Deploy it on local docker server with command: pycloud deploy docker --file example.py * Check the deployment summary for api and monitoring console urls. API reference To start your adventure with PyCloud you need to initialize PyCloud object instance: CLOUD = PyCloud.get_instance() PyCloud is providing annotations, which will allow you to adjust your application architecture with minimal effort. Moreover PyCloud provides functions to communicate between endpoints both synchronously and asynchronously. @CLOUD.endpoint You can use this annotation to create new endpoint in microservice architecture. @CLOUD.endpoint has two parameters: service_id - this enable you to collect chosen endpoints in one service protocols - list of protocols which will be used to expose your endpoint . Currently PyCloud support protocols: HTTP , GRPC , AMQP To make your already implemented endpoint available via GRPC protocol you only need to add this annotation: @CLOUD.endpoint(\"api\", protocols=[\"GRPC\"]) def get(): \"\"\"Endpoint implementation\"\"\" return result If you want to have more endpoints available in the same service you can simply add @CLOUD.endpoint to next function (with the same service_id=\"api\" ): @CLOUD.endpoint(\"api\", protocols=[\"GRPC\"]) def post(): \"\"\"Endpoint implementation\"\"\" return result This gives you great flexibility to choose which parts of application should be independent. With combination of deployment in Kubernetes cluster this gives you possibility to scale only some parts of your application. To add new, independent endpoint, just add @CLOUD.endpoint annotation with different service_id: @CLOUD.endpoint(\"processing\", protocols=[\"GRPC\"]) def processing(): \"\"\"Endpoint implementation\"\"\" return result @CLOUD.init_service Sometimes there is a need to initialize service with some data. For this purpose you can use @CLOUD.init_service annotation. @CLOUD.init_service(\"publish-service\") def initialize_publisher(): return {\"data\": \"something\"} Than you can retrieve data: @CLOUD.endpoint(\"publish-service\", protocols=['AMQP']) def publish(result): data = CLOUD.initialized_data() LOGGER.info(\"Result is : {}, and the data is: {}\".format(result, data)) CLOUD.call() This method is used to combine to endpoints synchronously. Here is example of API endpoint which is taking image and sending it synchronously to second service called pre_process . Please notice that with this approach you are able to scale independently your api and pre_process services. @CLOUD.endpoint(\"api\", protocols=[\"GRPC\"]) def api(image): result = CLOUD.call(pre_process, image) return result CLOUD.message() Alternative to CLOUD.call() is asynchronous CLOUD.message() . First step is to create asynchronous consumer endpoint based on AMQP - Advanced Message Queuing Protocol @CLOUD.endpoint(\"asynchronous-consumer\", protocols=[\"AMQP\"]) def asynchronous_consumer(message): LOGGER.info(\"Just received asynchronous message :%s\", message) Second step is creation of endpoint which will use above asynchronous endpoint : @CLOUD.endpoint(\"postprocessing\") def postprocess(results): \"\"\" Convert model output to string label\"\"\" index = np.argmax(results) LOGGER.info(\"Detected class number: %d\", index) label = IMAGENET_LABELS[index] CLOUD.message(asynchronous_consumer, label) return label Console TBD CLI $ pycloud -h usage: pycloud [-h] {version,deploy,update,ls,clean} ... positional arguments: {version,deploy,update,ls,clean} commands version display PyCloud and PyCloud-cli versions deploy deploy PyCloud services update not implemented ls not implemented clean not implemented optional arguments: -h, --help show this help message and exit $ pycloud deploy -h usage: pycloud deploy [-h] --file FILE [--dev-mode DEV_MODE] {docker,gke} positional arguments: {docker,gke} Deploy to one of the possible environments optional arguments: -h, --help show this help message and exit --file FILE, -f FILE path to file with PyCloud deployment specification --dev-mode DEV_MODE development mode","title":"Welcome to PyCloud!"},{"location":"#welcome-to-pycloud","text":"PyCloud is a solution for creating scalable cloud deployments with Python. It translates local Python code into kubernetes cluster with minimal number of extra logic (no more handcrafting yaml files). That allows easy and fast transformation of algorithms/AI code into cloud environment. Because it's fast, it gives flexibility not known before - adjusting architecture/redeployment for better scalability can be done in minutes.","title":"Welcome to PyCloud!"},{"location":"#getting-started","text":"Create and enter python virtualenv virtualenv -p python3 .venv && . .venv3/bin/activate Download pycloud-cli from https://pycloud.ai/download Run pycloud-cli init command Check and download one of the examples on github Deploy it on local docker server with command: pycloud deploy docker --file example.py * Check the deployment summary for api and monitoring console urls.","title":"Getting started"},{"location":"#api-reference","text":"To start your adventure with PyCloud you need to initialize PyCloud object instance: CLOUD = PyCloud.get_instance() PyCloud is providing annotations, which will allow you to adjust your application architecture with minimal effort. Moreover PyCloud provides functions to communicate between endpoints both synchronously and asynchronously.","title":"API reference"},{"location":"#cloudendpoint","text":"You can use this annotation to create new endpoint in microservice architecture. @CLOUD.endpoint has two parameters: service_id - this enable you to collect chosen endpoints in one service protocols - list of protocols which will be used to expose your endpoint . Currently PyCloud support protocols: HTTP , GRPC , AMQP To make your already implemented endpoint available via GRPC protocol you only need to add this annotation: @CLOUD.endpoint(\"api\", protocols=[\"GRPC\"]) def get(): \"\"\"Endpoint implementation\"\"\" return result If you want to have more endpoints available in the same service you can simply add @CLOUD.endpoint to next function (with the same service_id=\"api\" ): @CLOUD.endpoint(\"api\", protocols=[\"GRPC\"]) def post(): \"\"\"Endpoint implementation\"\"\" return result This gives you great flexibility to choose which parts of application should be independent. With combination of deployment in Kubernetes cluster this gives you possibility to scale only some parts of your application. To add new, independent endpoint, just add @CLOUD.endpoint annotation with different service_id: @CLOUD.endpoint(\"processing\", protocols=[\"GRPC\"]) def processing(): \"\"\"Endpoint implementation\"\"\" return result","title":"@CLOUD.endpoint"},{"location":"#cloudinit_service","text":"Sometimes there is a need to initialize service with some data. For this purpose you can use @CLOUD.init_service annotation. @CLOUD.init_service(\"publish-service\") def initialize_publisher(): return {\"data\": \"something\"} Than you can retrieve data: @CLOUD.endpoint(\"publish-service\", protocols=['AMQP']) def publish(result): data = CLOUD.initialized_data() LOGGER.info(\"Result is : {}, and the data is: {}\".format(result, data))","title":"@CLOUD.init_service"},{"location":"#cloudcall","text":"This method is used to combine to endpoints synchronously. Here is example of API endpoint which is taking image and sending it synchronously to second service called pre_process . Please notice that with this approach you are able to scale independently your api and pre_process services. @CLOUD.endpoint(\"api\", protocols=[\"GRPC\"]) def api(image): result = CLOUD.call(pre_process, image) return result","title":"CLOUD.call()"},{"location":"#cloudmessage","text":"Alternative to CLOUD.call() is asynchronous CLOUD.message() . First step is to create asynchronous consumer endpoint based on AMQP - Advanced Message Queuing Protocol @CLOUD.endpoint(\"asynchronous-consumer\", protocols=[\"AMQP\"]) def asynchronous_consumer(message): LOGGER.info(\"Just received asynchronous message :%s\", message) Second step is creation of endpoint which will use above asynchronous endpoint : @CLOUD.endpoint(\"postprocessing\") def postprocess(results): \"\"\" Convert model output to string label\"\"\" index = np.argmax(results) LOGGER.info(\"Detected class number: %d\", index) label = IMAGENET_LABELS[index] CLOUD.message(asynchronous_consumer, label) return label","title":"CLOUD.message()"},{"location":"#console","text":"TBD","title":"Console"},{"location":"#cli","text":"$ pycloud -h usage: pycloud [-h] {version,deploy,update,ls,clean} ... positional arguments: {version,deploy,update,ls,clean} commands version display PyCloud and PyCloud-cli versions deploy deploy PyCloud services update not implemented ls not implemented clean not implemented optional arguments: -h, --help show this help message and exit $ pycloud deploy -h usage: pycloud deploy [-h] --file FILE [--dev-mode DEV_MODE] {docker,gke} positional arguments: {docker,gke} Deploy to one of the possible environments optional arguments: -h, --help show this help message and exit --file FILE, -f FILE path to file with PyCloud deployment specification --dev-mode DEV_MODE development mode","title":"CLI"}]}